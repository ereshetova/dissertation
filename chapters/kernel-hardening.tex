
It is easy to see that a central piece of any platform security architecture is the security of the operating system (OS) kernel: any breach in this area almost always leads to a compromise of the whole system, especially if no security hardware support is present. This makes the OS kernel a very attractive target and recent studies~\cite{stoep2016android},~\cite{tolvanen2017},~\cite{windowsexploits} as well as increased number of kernel Common Vulnerabilities and Exposures (CVE) reports~\cite{nistCves} show that adversaries are focusing their efforts more and more on kernel-level attacks. This is especially true given that many popular mobile and embedded OSes have spent considerable effort in tightening the security of their userspace applications and processes~\cite{stoep2016android},~\cite{tolvanen2017}. For example, it used to be pretty common that many userspace daemons ran with superuser privileges all the time making it very easy for attackers to obtain these privileges right after compromising a single userspace process. On the contrary, nowadays the privileges of each userspace application or daemon are minimized, and higher privileges are quite commonly even limited to the system or daemon startup time: after the initialization phase is finished, unnecessary privileges are dropped and cannot be misused by an attacker if the process gets compromised later on. Another common improvement is compartmentalization and isolation of the most vulnerable application parts, such as parsers and renderers, into separate sandboxed processes further reducing attacker's opportunities. As a result of these efforts, modern successful attacks on userspace applications are very complex and require chaining of multiple vulnerabilities in order to reach the desired result. In contrast, a single vulnerability directly in the OS kernel provides an attacker with superuser privileges right away.

This dissertation focuses on a specific OS kernel, namely the Linux kernel, due to its widespread adoption for mobile and embedded devices: more than 2 billion mobile devices were already running Android OS powered by the Linux kernel~\cite{googleio2017} at the end of 2017, and many embedded manufacturers build their OSes based on Open Embedded/Yocto~\cite{OE2017, yocto2017} projects with the Linux kernel at its base etc. 
In addition, the Linux kernel is developed fully in the open and any person is able to propose ideas or contribute code to the mainline (of course assuming that the Linux kernel maintainers agree with the approach).

\textbf{Protecting the Linux kernel:}   Past studies~\cite{stoep2016android, cooklss2016} show that Linux kernel vulnerabilities have remarkably long life times. It takes on average five years for fixing a vulnerability introduced into the kernel source code. Moreover, even after it is finally fixed in the mainline Linux kernel, it is very difficult to estimate when the fix will be delivered to the end devices: it might take anything between several days to a number of years. In addition, some older embedded or mobile devices might actually never see these updates, making them perfect attack targets. Thomas et al.~\cite{Thomas2015}, in 2015, showed that on average 87.7\% of Android devices are exposed to at least 11 known critical vulnerabilities including the ones in the Android OS kernel itself. The time window between the public announcement of kernel vulnerability and its fix (usually pretty fast) in the mainline kernel and the time the fix is propagated to most of the devices is the period of golden opportunity for many attackers: all the details about the vulnerability are known and sometimes even proof-of-concept exploits can be obtained.

As adversaries have been turning towards attacking the Linux kernel itself, security architects, researchers and engineers have been exploring various methods for its better protection. A lot of effort has been put into improving the overall testing suites for the Linux kernel, as well as various static and dynamic code checkers are also used regularly and automated. New tools, including better commit verification scripts are being developed to assist developers, better code review practices are established etc. However, it is unrealistic to assume that it would ever be possible to have all the bugs in the source code found and fixed even in the well-maintained mainline Linux kernel. The situation is even worse for drivers and other non-mainline code developed by original equipment manufacturers (OEM)~\cite{stoep2016android}. Such code might get very limited code review, little testing and be written under harsh time-to-market requirements making it a good place for introducing bugs and vulnerabilities.

An alternative approach that defenders can take is to consider how modern kernel exploits are written and try to eliminate all attack paths that helps exploit writers to succeed. This is exactly the path that the Kernel Self Protection Project (KSPP)~\cite{kspp} has taken. KSPP is an open community of developers and security experts that aims to develop new or adapt existing kernel hardening measures for the mainline Linux kernel. 

\textbf{Structure of kernel attacks:}   Figure~\ref{fig:exploit-steps} shows the two core run-time steps of a typical attack on the Linux kernel\footnote{In practice a kernel exploit usually has many more additional steps since an attacker needs to fingerprint the target in run-time, bypass various enabled protections, perform necessary information gathering, etc.}. The starting assumption is that an attacker already has a full control of a userspace process locally on the platform. While developing an exploit, an attacker usually spends a considerable amount of time to explore the target kernel offline in order to collect as much information about it as possible, search for a suitable bug(s) to exploit, etc. During this offline preparation step an attacker is able to get a full access to the kernel memory layout, various debugging and tracing tools etc. Preventing this step is impossible due to the open nature of the Linux operating system, but various protection methods can be employed to minimize the value of collected information. For example, Kernel Address Space Layout Randomization (KASLR)~\cite{cook2013} and other techniques such as \setype{GRKERNSEC\_RANDSTRUCT}~\cite{randstruct2017} can make sure that every time a Linux kernel is loaded on the system, the memory locations of many of its components are randomized, and therefore an attacker cannot use the information gathered in the offline preparation step to locate required kernel elements (modules, symbols, structures etc.) during the later steps of a run-time attack. 

\begin{figure}[t]
	\centering
		\includegraphics[width=1\textwidth]{figures/kernel_exploit_steps.png}
	\caption{Core steps of a Linux kernel attack. The focus areas of this dissertation are highlighted in light grey}
	\label{fig:exploit-steps}
\end{figure}    

In Step 1, an attacker needs to trigger a suitable bug that would allow him to obtain a read or write primitive inside the Linux kernel. There are many bug classes that can be used for this purpose and Figure~\ref{fig:exploit-steps} shows the most common ones for the Linux kernel. Some bug classes such as stack overflows, typically lead to a write primitive, while some, like temporal and spatial memory errors (see Section~\ref{sec:kern-mem-safety} for definitions) can lead to both of them depending on the code where the bug is present. The format string vulnerabilities typically lead to a read primitive, except in cases when the format string is using \setype{\%n} specifier that allows writing input data to a pointer (and as a result, a write primitive). Integer overflow/underflow bugs do not typically give a read or write primitive straight to an attacker, but they can be used to create other bug classes. For example, if an overflown integer is used to allocate a buffer, the resulting buffer is going to be of a smaller size than required leading to a buffer overflow bug (spatial memory error). Preventing Step 1 from happening would be the ideal case for defenders, but in reality it is very difficult and costly to fully prevent certain classes of bugs from happening. Nonetheless, a lot of work is being done in this area within KSPP and Section~\ref{sec:kern-mem-safety} of this dissertation addresses the problem of preventing a wide range of memory errors (both temporal and spatial) in the Linux kernel. 

In Step 2, an attacker can finalize the exploitation using the bug(s) found in Step 1. In case of a read primitive, the end result is usually a run-time kernel memory leak that can be either valuable on its own (various sensitive information, such as keys and credentials) or can be used as supporting information for launching further attack steps using another kernel bug. In turn, a write primitive can be used by an attacker to modify either a code-related pointer or the dereferencing of a kernel data pointer or structure. The code-related pointer can be either directly an instruction pointer (as is the case with stack overflow attacks) or a function pointer located in places such as function pointer's tables or descriptor's tables. All of this would allow an attacker to redirect the execution flow to a desired place. That place can be either the kernel's own executable memory (by building and chaining the available attack gadgets in an return-oriented programming (ROP)-like technique~\cite{Shacham2007} or using mechanisms like just-in-time (JIT) compilers~\cite{Aycock03abrief}) or the userspace (various \textit{ret2usr} attacks~\cite{Kemerlis2012}), where an attacker usually has more control over the memory layout and more mechanisms for continuing the attack and making it persistent over reboots. An attacker can also modify a data pointer (commonly to a structure located in the userspace) that might allow him to perform various data-only attacks. Many different protections can be put in place in order to prevent Step 2 from happening, but they are not generic and depend on the chosen attack path. For example, in order to prevent a function pointer overwrite, function pointer tables can be made read-only after the kernel initialization step. Similarly, in order to prevent a direct modification of an instruction stack pointer, various return address protection techniques, such as stack canaries~\cite{edge2014}, guard pages~\cite{kstackoverflow2017} etc. can be employed.   

\textbf{Research questions:}   Within the KSPP project, this dissertation has investigated two important areas of kernel hardening that are highlighted in dark grey in Figure~\ref{fig:exploit-steps}). The first research question, discussed in Section~\ref{sec:bpf-jit-attack}, is \textit{\textbf{security of Berkeley Packet Filter (BPF) JIT compiler}}, i.e. whenever the mainline Linux BPF JIT compiler can be used in order to perform successful practical attacks. The BPF JIT compiler is the only JIT compiler in the Linux kernel that executes programs supplied by unprivileged userspace, making it a very valuable target for attackers.  The second research question, discussed in Section~\ref{sec:kern-mem-safety}, is \textbf{\textbf{\textit{runtime kernel memory safety}}}, i.e. the ability to prevent kernel memory errors, such as use-after-frees or buffer overflows in runtime. Addressing these memory errors can greatly affect the overall security of the Linux kernel and help eliminate many past and future vulnerabilities. The subsections below explain each aspect in more detail as well as the contribution this dissertation makes in addressing these two research questions.  

\section{Security of Berkeley Packet Filter Just-In-Time compiler}
\label{sec:bpf-jit-attack}

Having an OS kernel mechanism with the ability to execute userspace-supplied code is always very attractive for attackers. 
The mainline Linux kernel has such a mechanism: the Berkeley Packet Filter (BPF)~\cite{kernelfilter2016} and the associated Just-In-Time (JIT) compiler, that is basically an in-kernel virtual machine available for unprivileged execution from userspace. Historically, this mechanism was introduced to speed up packet filtering on networking sockets, but nowadays it is also used in a wide range of non-networking applications, including trace points~\cite{starovoitov2015}, syscalls filtering in seccomp~\cite{seccomp2016}, Kernel Connection Multiplexer (KCM)~\cite{corbet2015} etc. There is even a proposal to use BPF for creating a user-programmable Linux Security Module, Landlock~\cite{landlock2016}, that considerably widens the set of BPF use cases.

\begin{figure}[t]
	\centering
		\includegraphics[width=0.80\textwidth]{figures/bpf-overview.png}
	\caption{Linux kernel Berkeley Packet Filter and JIT compiler (Adapted from Publication V)}
	\label{fig:bpf-overview}
\end{figure}


The overall flow of how a BPF program is processed by the kernel is shown in Figure~\ref{fig:bpf-overview}.  
A userspace process expresses its packet filtering algorithm in the form of a BPF program and attaches it to a socket (steps 1-3). A BPF program is written in the BPF interpreter language that can be executed by BPF in the kernel. When a BPF program is loaded to the kernel (step 4), it is first verified by a BPF Verifier component that attempts to check the correctness of the supplied program (step 5). If the check fails, the program is discarded (step 6). If the check passes, then the program is attached to the socket and will be executed every time the packet is received for that socket. For non-networking scenarios, a BPF program will be executed every time a certain action is performed by its creator, i.e. for the seccomp system calls (syscalls) filtering, a BPF program will be invoked every time a process executes a system call. In addition, in order to further speed up the filtering, the BPF program can be given to the JIT compiler (step 7) that translates it to native machine assembly language (step 8). This is typically enabled for high-performance networking use cases and disabled on a typical desktop system.  

The above flow can be abused to load the attacker-supplied payload into the kernel memory using an attack technique called \textit{JIT spraying}~\cite{blazakis2010, bania2010jit}. The original proof-of-concept exploit was done back in 2012~\cite{mcallister2012attacking} and showed that BPF JIT compiler design and implementation are very vulnerable to such attacks. As a result, a protective measure was merged in the mainline kernel that attempted to randomize the start memory address within the page where the BPF program gets loaded and fill the rest of the page with architecture-specific instructions (aka \"poisoned zone\") that would hang the machine fully if the attacker tried to execute them. This made it really hard (with a probability of success of only about 0.0004\%) for an attacker to find the supplied payload. However, the root cause of the problem, i.e. the ability to supply the attacker payload in BPF programs using constants, was not fixed at that time, despite the suggestions from some security experts\footnote{The Grsecurity kernel security project \url{grsecurity.net}}.

Publication V of this dissertation analyzes the security issues of the BPF JIT compiler and builds a number of successful attacks on the latest (at that time) available mainline 4.4 Linux kernel despite the security fixes done in the past. 
Our best attack approach, described in Section 4.3 of publication V, analyzes how memory allocation for a BPF program happens and specifically how randomization of the start address is done in the mainline kernel implementation. 
This analysis discovered that for BPF programs of total size of \setype{PAGE\_SIZE - 128 - PROGRAM\_HEADER\_SIZE} (the size can be controlled by an attacker by adding more or less BPF instructions) the maximum size of the poisoned zone can be calculated in advance (equals to 128 bytes) and it allows an attacker to reliably jump over the poisoned zone and land securely on the BPF program payload. The resulting overall success rate for the attack is 99.6\%, which proves that much stronger security measures are required for the BPF JIT compiler in order to provide adequate security against JIT spray attacks. As a result of this work, a number of mitigation measures were merged to the mainline kernel that eliminated the possibility to perform these types of attacks\footnote{\url{git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=4f3446b}}. It is no longer possible to supply the attacker's payload in BPF programs using the constants due to the blinding process (XORing with a random number) done for each of them prior to its placement in the memory.

\section{Kernel memory safety}
\label{sec:kern-mem-safety}

Memory errors can be very dangerous for the security of an OS kernel since they can give an attacker the ability to read or write kernel memory, which is normally inaccessible for a userspace process. The cause of these errors is the absence of inherent memory safety in C, which is the primary implementation language of the Linux kernel. 
Numerous past CVEs (CVE-2014-2851, CVE-2016-4558, CVE-2016-0728, CVE-2014-0196, CVE-2016-8440, CVE-2016-8459, and CVE-2017-7895) as well as vulnerability studies~\cite{raheja2016analysis, chen2011linux} show that memory errors are a big problem for the Linux kernel and need addressing in order to be more robust against these attacks.

Typically, memory errors are divided into two classes:

\begin{itemize}
	\item \textbf{Temporal memory errors} happen when pointers to uninitialized or freed memory are dereferenced. A typical example is a \emph{use-after-free} error when a memory that is dereferenced by the pointer has already been prematurely freed. Another example are null pointer dereference errors, when an initialized pointer is attempted to be dereferenced. 
	\item \textbf{Spatial memory errors} occur when pointers are dereferenced outside the bounds of their intended areas. The most common example here is a buffer overflow, when data is written past the end of the memory area allocated for the buffer. 
\end{itemize}

Memory safety has been researched for decades both in academia and industry.
Many solutions have been proposed to fully eliminate the root cause of the problem, but they are rarely used in practice due to the significant side effects they bring. 
The primary issue is usually the performance; most of the developed solutions~\cite{hastings1991purify},~\cite{patil1995efficient},~\cite{patil1997low},~\cite{nagarakatte2009softbound},~\cite{jones1997backwards},~\cite{yong2003protecting},~\cite{xu2004efficient},~\cite{nethercote2004bounds}, and ~\cite{dhurjati2006backwards} incur a significant and non-acceptable run-time performance overhead.
Other typical issues are lack of backwards compatibility~\cite{necula2002ccured},~\cite{grossman2005cyclone},~\cite{austin1994efficient} and the need to make source code changes~\cite{necula2002ccured},~\cite{grossman2005cyclone}. 
In addition, almost all existing mechanisms were developed for the userspace and have not been considered for in-kernel use with the exception of recently developed kCFI~\cite{Rigo} and KENALI~\cite{kenali}. However, even these systems have not been developed with the goal of merging them into the mainline Linux kernel and therefore exhibit some design choices, such as a requirement to have two compilation rounds, that won't be acceptable to mainline kernel developers\footnote{\url{http://www.openwall.com/lists/kernel-hardening/2017/08/05/1}}. 

Publication VI of this dissertation takes a deep look at both temporal and spatial memory problems in the Linux kernel and proposes two practical measures that address each of these types of errors. 

\subsection{Preventing temporal memory errors for objects protected by a reference counter}
\label{sec:kern-mem-ref-count}

The lifetime of a shared object in the Linux kernel is typically managed using a \textbfit{reference counter}. 
Such a counter is incremented every time a reference to an object is taken and decremented when a reference is released. 
When the counter reaches zero the object can be safely deleted since there are no references to this object anymore (object is not used).

The above presents a simple logic, but practice and the history of Linux kernel vulnerabilities (for example CVE-2014-2851, CVE-2016-4558, CVE-2016-0728, CVE-2017-7487 and CVE-2017-8925) shows that reference counting schemes are error prone. If a developer forgets to perform an increment or decrement in some code branch (quite often on a rarely exercised error-handling or exception path), it might lead to counter imbalance and as a result incorrect object lifetime handling, i.e. a use-after-free situation on the object. This can be misused by attackers in order to construct efficient and simple kernel exploits: an attacker needs to allocate a different kernel object (but with a user-controlled content) from userspace over the same memory that is going to be mistakenly freed and then use the reference to the old object to trigger the code execution. One such example is the exploit based on kernel CVE-2016-0728\footnote{\url{https://www.exploit-db.com/exploits/39277/}}. The exploit abuses a bug inside the kernel keyring facility: a forgotten decrement of the reference counter when an attacker asks to substitute the session keyring with exactly the same keyring. 
The problem is even bigger given the fact that the current implementation of reference counters in the Linux mainline kernel allows a counter to overflow upon reaching its maximum value (specific to the architecture). 

The first part of Publication VI analyzes how developers have used reference counters in the Linux kernel and describes the design of a new reference counter data type \setype{refcount\_t} and its API that prevents reference counter overflows by its internal design. 
The new type is specifically designed for the reference counting use only and therefore has a much more limited API compared to the generic type, \setype{atomic\_t}, which is used not only for reference counters but also for many other purposes. This makes it possible to reduce potential development errors when implementing reference counters and improves the code review process.   
This type and the respective API have been accepted into the mainline Linux kernel and are becoming the de-facto standard for implementing reference counters. 
Paper VI also presents an overall kernel-wide analysis and conversion of existing reference counters to \setype{refcount\_t} that resulted in more than 170 accepted patches as of March 2018. The analysis was done using a static analyzer, Coccinelle~\cite{coccinelle}, integrated into the Linux Kernel build system (KBuild). A set of code patterns was developed for this purpose that identify reference counters based on their behavior, i.e. freeing an object upon the counter reaching zero. These code patterns are explained in more detail in Section 4.1 of Publication VI. After the automatic analysis was completed, each case was manually analyzed and a respective patch created. 


\subsection{Preventing out-of-bounds memory accesses}
\label{sec:kern-mem-out-of-bounds}

As was already mentioned in Section~\ref{sec:kern-mem-safety}, none of the existing run-time mechanisms to handle memory access errors are directly applicable to the mainline Linux kernel. However, some mechanisms are commonly used for debugging purposes.
KASAN~\cite{kasan}, integrated in the mainline Linux kernel, is perhaps the most known of them all. It enables detection of a wide range of memory errors, including spatial ones. However, its performance overhead is unsuitable for most production use cases.
In the userspace, the popular analogs of KASAN are Valgrind~\cite{nethercote2007valgrind} and AddressSanitizer~\cite{serebryany2012addresssanitizer} tools. 

Recently, Intel released a new technology, \intel Memory Protection Extensions (MPX)~\cite{ramakesavan2015intel}, for hardware-assisted run-time prevention of spatial memory errors.  Similar to many related solutions~\cite{jones1997backwards},~\cite{nagarakatte2009softbound}, MPX determines (either during compile time or during the run-time) the correct bounds for each used pointer and stores this data in the separated metadata storage. Pointer bounds are enforced by MPX instrumentation using added hardware instructions, essentially by checking memory addresses before dereferencing pointers. The checks are done against bounds set by compiler instrumentation, either statically based on data structure sizes, or during execution by instrumented allocators. The above software support is implemented both in the Linux kernel and the GNU Compiler Collection (GCC) compiler, but until recently, this software support only worked for user-space applications. 
 
The second part of Publication VI analyzes the software implementation of \intel Memory Protection Extensions (MPX) as well as various challenges of using MPX for the Linux kernel itself. The major challenge was the high memory overhead incurred by the mechanism by which MPX stores the bounds for pointers. If such a mechanism is directly applied to the Linux kernel, it would result in more than a $500\%$ increase for the kernel base memory, which is unacceptable. The on-demand memory allocation mechanism for the userspace, used by MPX in an attempt to minimize its memory consumption, is also very hard to implement reliably for the Linux kernel itself due to many possible deadlocks it might create. Other challenges included an inability to use the MPX initialization code created for the userspace, userspace function wrappers, as well as the GCC compiler support directly for the kernel code.
As a result, Publication VI proposes a new mechanism, \emph{MPX for Kernel (MPXK)}, which is an adaptation of \intel MPX for in-kernel use where all the above described challenges have been solved. MPXK does not use the costly memory storage mechanism of MPX, but instead re-uses the kernel memory management metadata created by \setype{kmalloc}-based allocators. This results in a small memory footprint, but has some limitations (such as reduced coverage since not all pointers in the kernel are allocated using \setype{kmalloc}-based allocators) explained in detail in Sections 5.1 and 6.1 of Publication VI. MPXK also implements all the missing GCC compiler instrumentation in the form of a new GCC plugin, as well as does in-kernel initialization of MPX and function wrappers to pass the bounds metadata. 

\section{Discussion}

%In order to do a high-level evaluation of the solutions proposed in this chapter and their impact on the researched area, it is important to start from the original objectives defined in Section~\ref{sec:Objectives}: security, practical deployability and usability. A more formal and detailed evaluation of solutions proposed in this chapter can be found in the evaluation sections of Publications V and VI. 

The attacks described in Section~\ref{sec:bpf-jit-attack} address the \textit{\textbf{security of Berkeley Packet Filter (BPF) JIT compiler}} research question and built a strong case for the mainline acceptance of BPF JIT blinding protections that considerably improved the security of Linux kernel BPF/JIT. Originally, these attacks were possible because the blinding solution developed by Grsecurity~\cite{grsecurity} was considered as an unnecessary complication to the BPF JIT functionality impacting code maintainability and performance. And since the only existing practical 2012 proof-of-concept exploit~\cite{mcallister2012attacking} could be stopped with much simpler measures (start address randomization and poisoning zone), the constant blinding technique was not implemented in the mainline kernel until the work described in Publication V. 

The measures to harden Linux kernel reference counters, described in Section~\ref{sec:kern-mem-ref-count}, partially address the \textbf{\textit{runtime kernel memory safety}} research question for the temporal memory errors. They aim to significantly decrease hard-to-find developer mistakes in reference counter usage and therefore prevent resulting use-after-free situations on shared kernel objects. Had such measures been in place, they would have prevented many kernel vulnerabilities mentioned in Section~\ref{sec:kern-mem-ref-count}. The newly introduced \setype{refcount\_t} type and API guarantee that a reference counter cannot overflow under any condition, and our kernel-wide conversion of reference counters to \setype{refcount\_t} (175 from 220) provides a good initial code coverage with more and more conversions added in each kernel release. While the overall effectiveness of this measure would be only possible to judge with time, the proposed solution is also practically deployable and usable: it exhibits acceptable performance overhead for most workloads, can be applied on a case-by-case basis and it has been taken into use by its main intended users, kernel developers and maintainers. 

The MPXK mechanism, described in Section~\ref{sec:kern-mem-out-of-bounds}, address the \textbf{\textit{runtime kernel memory safety}} research question for the spatial memory errors. It aims to protect the Linux kernel from all such errors and therefore prevent a wide class of attacks caused by them. MPXK ensures that pointers to the objects with known bounds cannot be dereferenced outside of these bounds. However in some cases the correct bounds cannot be reliably determined and therefore MPXK has a number of limitations connected with usage of legacy code, type of memory allocation and some cases of direct pointer manipulations. The practical deployability of MPXK is judged based on a small performance overhead and the ability to apply the protection only in required places (with a compilation unit granularity) compared to system-wide solutions like KASAN. MPXK does not require any source code changes and it is fully integrated into the kernel build infrastructure making it easy for kernel developers to enable protection where required.  

Recently, a new set of powerful attacks, named Spectre~\cite{Kocher2018spectre} and Meltdown~\cite{Lipp2018meltdown}, forced additional protective measures to be merged into the mainline Linux kernel. The attacks work by tricking a victim into speculatively performing some operations that would not normally occur during the program operation flow. As a result of this speculative execution, one can leak the victim's confidential information (such as various security credentials or simply the content of the kernel memory) via a side channel (typically a cache-based) to the attacker. The first protective measure, Kernel Page-Table Isolation (KPTI)~\cite{kpti}, was merged into the mainline Linux kernel at the end of 2017 and aims to mitigate the Meltdown attack. It isolates the kernel page tables from the userspace and therefore removes the possibility to speculatively prefetch the kernel mapped data by a userspace process. While this measure does help in protecting against the Meltdown attack, it also exhibits a significant performance downgrade~\cite{kptiperf}. The other measure~\cite{variant1}, merged into the mainline Linux kernel, provides mitigation for the Spectre attack. It works by sanitizing the dereferencing of arrays in the kernel code to remove the possibility of speculatively addressing a kernel array or a kernel pointer beyond its bounds. The downside of this measure is that in order to be effective, it needs to be used in each potentially vulnerable place in the kernel source code.     
